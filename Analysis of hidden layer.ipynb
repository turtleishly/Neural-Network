{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4b48641c",
   "metadata": {},
   "source": [
    "do a two layer NN (16,10) - use vectorized math (but still try sigmoid first), do step by step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "7f0dfd0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "data = pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "2eb34618",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x): #sigmoid func to squish all inputs into range 0 to 1\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def sigmoid_derivative(x): #derivative of sigmoid\n",
    "    return sigmoid(x) * (1 - sigmoid(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "f4bceacd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\nGiven two vectors, a = [a0, a1, ..., aM] and b = [b0, b1, ..., bN], the outer product 1 is:\\n\\n  [[a0*b0  a0*b1 ... a0*bN ]\\n   [a1*b0    .\\n   [ ...          .\\n   [aM*b0            aM*bN ]]\\n'"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# np.outer(a, b)\n",
    "'''\n",
    "\n",
    "Given two vectors, a = [a0, a1, ..., aM] and b = [b0, b1, ..., bN], the outer product 1 is:\n",
    "\n",
    "  [[a0*b0  a0*b1 ... a0*bN ]\n",
    "   [a1*b0    .\n",
    "   [ ...          .\n",
    "   [aM*b0            aM*bN ]]\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "38e8c507",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training data management\n",
    "data= np.array(data)\n",
    "\n",
    "#Train test split 80:20\n",
    "test_datas = data[int(len(data)*0.8):]\n",
    "train_datas = data[:int(len(data)*0.8)]\n",
    "\n",
    "#Separating pixel data and label data\n",
    "train_labels = train_datas[:,0] #label col\n",
    "train_datas = (train_datas[:,1:] - np.min(train_datas[:,1:]))/(np.max(train_datas[:,1:])-np.min(train_datas[:,1:])) # pixel data, scaled to 0-1\n",
    "\n",
    "test_labels = test_datas[:,0] #label col\n",
    "test_datas = (test_datas[:,1:] - np.min(test_datas[:,1:]))/(np.max(test_datas[:,1:])-np.min(test_datas[:,1:])) # pixel data, scaled to 0-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "67ff502b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialization of weights and biases\n",
    "\n",
    "weights = [] #list to store all the weights for every layer\n",
    "biases = [] #list to store all the biases for every layer\n",
    "\n",
    "size = [16, 10] #size of each layer, first layer is input layer, last layer is output layer\n",
    "\n",
    "train_data = train_datas \n",
    "train_label = train_labels\n",
    "\n",
    "for i in range(len(size)): #Initialize weights for each layer\n",
    "    if i == 0:\n",
    "        weights.append(np.random.randn(size[0], len(train_data[0])) * np.sqrt(1/len(train_data[0])))\n",
    "    else:\n",
    "        weights.append(np.random.randn(size[i], size[i-1]) * np.sqrt(1/size[i-1]))\n",
    "\n",
    "for i in range(len(size)):  #Initialize biases for each layer\n",
    "    if i == 0:\n",
    "        biases.append(np.zeros(size[0])) #First layer biases\n",
    "    else:\n",
    "        biases.append(np.zeros(size[i]))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "0eb5c530",
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in range(100): #Training loop, 100 epochs\n",
    "    for i in range(1000): \n",
    "        #Forward pass\n",
    "\n",
    "        z = weights[0] @ train_data[i] + biases[0] #First layer\n",
    "        a = sigmoid(z)\n",
    "\n",
    "        z_1 = weights[1] @ a + biases[1] #output layer\n",
    "        a_1 = sigmoid(z_1)\n",
    "\n",
    "\n",
    "        #loss calculation (Loss vs Cost, Loss = 1 example, cost = average)\n",
    "\n",
    "        one_hot = np.zeros(10)\n",
    "        one_hot[train_label[i]] = 1\n",
    "\n",
    "        loss = np.sum((a_1 - one_hot)**2)\n",
    "\n",
    "        #loss calculation (Loss vs Cost, Loss = 1 example, cost = average)\n",
    "\n",
    "        one_hot = np.zeros(10)\n",
    "        one_hot[train_label[i]] = 1\n",
    "\n",
    "        loss = np.sum((a_1 - one_hot)**2)\n",
    "\n",
    "        # output layer Backpropagation\n",
    "\n",
    "        dCda_1 = 2 * (a_1 - one_hot) #Derivative of cost w.r.t output layer activation\n",
    "        dCdz_1 = dCda_1 * sigmoid_derivative(z_1) #Derivative of C w.r.t output layer z (dCda_1 * da_1dz_1)\n",
    "\n",
    "        dCdw_1 = np.outer(dCdz_1, a) #Derivative of C w.r.t weights of output layer (dCdz_1 * dz_1da_1 * da_1dw_1) #It was this simple??\n",
    "        dCdb_1 = dCdz_1 #Derivative of C w.r.t biases of output layer (dCdz_1 * dz_1db_1 * db_1)\n",
    "        weights[1] -= 0.01 * dCdw_1 #Update weights of output layer\n",
    "        biases[1] -= 0.01 * dCdb_1 #Update biases\n",
    "\n",
    "                #16x10   #Size 10, so need transpose\n",
    "        dCda = weights[1].T @ dCdz_1 #Derivative of C w.r.t activation of first layer (dCdz_1 * dz_1da_1 * da_1da)\n",
    "\n",
    "        # First layer Backpropagation\n",
    "        dCdz = dCda * sigmoid_derivative(z) \n",
    "\n",
    "        dCdw = np.outer(dCdz, train_data[i])\n",
    "        dCdb = dCdz\n",
    "        weights[0] -= 0.01 * dCdw\n",
    "        biases[0] -= 0.01 * dCdb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "737f2630",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.011554974624645366"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "ca6886f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "evaluation= [0.02579583 0.01543922 0.01920598 0.00736364 0.00195674 0.04516352\n",
      " 0.00124296 0.01011642 0.96458391 0.03115745] max=  8  label=  8\n"
     ]
    }
   ],
   "source": [
    "#Forward propagation, test a single example\n",
    "m = 10 #Example to test\n",
    "z = weights[0] @ train_datas[m] + biases[0] #First layer\n",
    "a = sigmoid(z)\n",
    "\n",
    "z_1 = weights[1] @ a + biases[1] #Following layers\n",
    "a_1 = sigmoid(z_1)\n",
    "\n",
    "print(\"\\nevaluation=\",a_1,\"max= \",np.argmax(a_1),\" label= \",train_labels[m])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "7222eddf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.975\n"
     ]
    }
   ],
   "source": [
    "#Check accuracy on training set\n",
    "correct = 0\n",
    "k = 1000\n",
    "for i in range(k):\n",
    "    z = weights[0] @ train_datas[i] + biases[0] #First layer\n",
    "    a = sigmoid(z)\n",
    "\n",
    "    for j in range(len(size)-1): \n",
    "        z = weights[j+1] @ a + biases[j+1] #Following layers\n",
    "        a = sigmoid(z)\n",
    "\n",
    "    if train_labels[i] == np.argmax(a): #np.argmax(a)\n",
    "        correct += 1\n",
    "        \n",
    "print(correct/k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "70d49dbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8845238095238095\n"
     ]
    }
   ],
   "source": [
    "#Check accuracy on test set\n",
    "correct = 0\n",
    "\n",
    "for i in range(len(test_datas)):\n",
    "    z = weights[0] @ test_datas[i] + biases[0] #First layer\n",
    "    a = sigmoid(z)\n",
    "\n",
    "    for j in range(len(size)-1): \n",
    "        z = weights[j+1] @ a + biases[j+1] #Following layers\n",
    "        a = sigmoid(z)\n",
    "\n",
    "    if test_labels[i] == np.argmax(a): #np.argmax(a)\n",
    "        correct += 1\n",
    "\n",
    "print(correct/len(test_datas))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "0f650ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "img = Image.open(\"number.png\") #Replace your_image.jpg with the path to your image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "9d45f13c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAYAAAByDd+UAAAA30lEQVR4nO2VuxGEMAxE5YsoTWWoDDqhBMqglA0JCRXqAgYCQODfMTBzO6PItp4xu3YgIqMb9bkT9geuYmYCQGa2FgASkSyoecXMBsDOBMBExO1xUD5smqZT2CJVLQeO47hr3HWdEZG1bbsbKwaq6g60rarA5Ss8GDPXBV6Zaft/fwL0XOudQhHQc+0wDKknFDfRy6Oq1smhZ6IK0HTTHG0gIfx5wCNozJqwUHM1c2aFEC7nP/N5egRQRAhA1tpok1y9j5F94oFnsITrLT8Gfd9b0zRJUSqORare49LXAL+Y2eevQBBMfQAAAABJRU5ErkJggg==",
      "text/plain": [
       "<PIL.PngImagePlugin.PngImageFile image mode=RGBA size=28x28>"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "a9c90b62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "img_array = np.array(img)\n",
    "img_array = (img_array[:,:,0]).flatten()\n",
    "img_array = (img_array - np.min(img_array)) / (np.max(img_array) - np.min(img_array))\n",
    "\n",
    "\n",
    "z = weights[0] @ img_array + biases[0]\n",
    "a = sigmoid(z)\n",
    "\n",
    "z_1 = weights[1] @ a + biases[1]\n",
    "a_1 = sigmoid(z_1)\n",
    "\n",
    "print(np.argmax(a_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd6230fd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
